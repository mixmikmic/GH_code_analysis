import pandas as pd
import urllib
import json
import requests
import os
import glob
from collections import defaultdict
import qtools
from tqdm import tnrange, tqdm_notebook

pd.set_option("display.max_columns",500)
host = 'https://www.encodeproject.org'
experiments = "https://www.encodeproject.org/experiments/"
date = '3-9-2017'
annotated_manifest_hepg2 = '/home/bay001/projects/maps_20160420/permanent_data/RNASeq_final_exp_list_HepG2.csv'
annotated_manifest_k562 = '/home/bay001/projects/maps_20160420/permanent_data/RNASeq_final_exp_list_K562.csv'
downloaded_dir = '/projects/ps-yeolab3/encode/rnaseq/shrna_knockdown_graveley_tophat/'

hepg2_df = pd.read_table(annotated_manifest_hepg2)
k562_df = pd.read_table(annotated_manifest_k562)

print("number of k562 rnaseq: ",k562_df.shape[0])
print("number of RBPs in K562",len(set(k562_df['Official_RBP'])))
print("number of Expts in K562",len(set(k562_df['RNA-Seq on K562'])))
print("number of Expts in Hepg2",len(set(hepg2_df['RNA-Seq on HepG2'])))
print("number of hepg2 rnaseq: ",hepg2_df.shape[0])
print("number of RBPs in Hepg2",len(set(hepg2_df['Official_RBP'])))
k562_df.head()

def get_expt_from_rbp(manifest_df, rbp, official=False, cell='HepG2'):
    """
    From the manifest generated by xintao, return the expt_id given an RBP name
    """
    colname = 'Official_RBP' if official else 'RBP'
    cellcol = 'RNA-Seq on HepG2' if cell == 'HepG2' else 'RNA-Seq on K562'
    return manifest_df[manifest_df[colname]==rbp][cellcol].to_string(index=False)
    
def star_or_tophat(link):
    """
    from the link, reads and returns whether or not STAR or TOPHAT are in the filename.
    """
    # print("LINK",os.path.basename(link))
    if os.path.basename(link).find('star') > -1:
        return 'STAR'
    if os.path.basename(link).find('tophat') > -1:
        return 'TOPHAT'
    return 'ambiguous'

def exists(fpath, current):
    """
    returns whether or not the file (fpath) exists in the directory(current)
    """
    base = os.path.basename(fpath.rstrip())
    if not os.path.exists(os.path.join(current,fpath)):
        return False
    else:
        return True
    
def exists_and_return_fullpath(fpath, current):
    """
    returns whether or not the file (fpath) exists in the directory(current)
    """
    base = os.path.basename(fpath.rstrip())
    if not os.path.exists(os.path.join(current,fpath)):
        return False
    else:
        return os.path.join(current,fpath)
    
def get_bams_from_expt_id(
    expt_id, assembly, aligner, lab
):
    """
    Given an expt id, return a list: [rbp name, [rep1bam, rep2bam], control_expt_id]
    
    control_expt_id is None if the expt_id given to this function is itself a control.
    
    """
    sample_bams = []
    control_expts = []
    
    experiments = "https://www.encodeproject.org/experiments/"
    url = experiments+expt_id+"/?format=json"
    response = urllib.urlopen(url)
    data = json.loads(response.read())
    if 'code' in data.keys():
        next
    else:
        for i in range(0,len(data['files'])):
            
            if (
                (host+data['files'][i]['href']).endswith('bam') & 
                (data['files'][i]['output_type'] == u'alignments') &
                (data['files'][i]['lab'][u'name'] == lab) &
                (star_or_tophat(data['files'][i]['submitted_file_name']) == aligner)
            ):
                if(data['files'][i]['assembly'] == assembly):
                    sample_bams.append(
                        {
                            'filename':os.path.basename(data['files'][i]['href']),
                            'md5sum':data['files'][i]['md5sum'],
                            'rep':int(data['files'][i]['replicate']['biological_replicate_number'])
                        }
                    )
        try:
            control_expts.append(data['possible_controls'][0]['accession'])
        except IndexError:
            pass
            # print("this is a control")
    if(len(control_expts) > 1):
        print("Warning, this expt {} has more than 1 associated control expt".format(expt_id))
    return data['target']['label'], sample_bams, control_expts

def make_expt_dataframe_from_expt_list(expt_list, assembly='hg19', aligner='STAR', lab='encode-processing-pipeline'):
    """
    Given a list of expt ids, return the reps and controls (and md5sums in case we need to check)
    """
    x = tnrange(len(expt_list))
    samples = defaultdict(dict)
    for h in expt_list:
        x.update(1)
        sname, s, control_expt = get_bams_from_expt_id(
            h, assembly, aligner, lab
        ) # gets the sample name, sample, and control expt id
        cname, c, _ = get_bams_from_expt_id(
            control_expt[0], assembly, aligner, lab
        ) # gets the control name, control
        for i in range(0,len(s)):
            samples_key = 'expt_rep{}'.format(s[i]['rep'])
            samples_md5sum_key = 'expt_rep{}_md5sum'.format(s[i]['rep'])
            control_key = 'control_rep{}'.format(s[i]['rep'])
            controls_md5sum_key = 'control_rep{}_md5sum'.format(s[i]['rep'])
            name_key = 'name'
            samples[h][name_key] = sname
            samples[h][samples_key] = s[i]['filename']
            samples[h][control_key] = c[i]['filename']
            samples[h][samples_md5sum_key] = s[i]['md5sum']
            samples[h][controls_md5sum_key] = c[i]['md5sum']
    bams = pd.DataFrame(samples).T
    return bams

hepg2_expts = list(set(hepg2_df['RNA-Seq on HepG2']))
k562_expts = list(set(k562_df['RNA-Seq on K562']))

aligner = 'ambiguous' # graveley lab pipeline doesn't adhere to the same file name structure as encode processing pipeline, but we trust that it's all tophat-aligned.
lab = 'brenton-graveley' # or 'encode-processing-pipeline'

hepg2_bams = make_expt_dataframe_from_expt_list(hepg2_expts, assembly='hg19', aligner=aligner, lab=lab)
k562_bams = make_expt_dataframe_from_expt_list(k562_expts, assembly='hg19', aligner=aligner, lab=lab)
print(hepg2_bams.shape)
print(k562_bams.shape)

k562_bams

hepg2_bams.to_csv(
    '/projects/ps-yeolab3/encode/hepg2_{}_{}_bams_for_integrated_analysis.txt'.format(lab, aligner),sep='\t'
)
k562_bams.to_csv(
    '/projects/ps-yeolab3/encode/k562_{}_{}_bams_for_integrated_analysis.txt'.format(lab, aligner),sep='\t'
)

def already_checked_md5sum(filepath, md5sum_checked_file):
    """
    given filepaths list, check the md5sum_checked_file to see if any file has been checked.
    Parameters
    ----------
    filepath : list
        list of files
    md5sum_checked_file : file
        dataframe of files
        
    returns list of files that haven't been checked.
    """
    exists_in_file = get_ipython().getoutput('grep $filepath $md5sum_checked_file')
    if len(exists_in_file) > 0:
        if "no such file" not in exists_in_file[0]:
            # print(exists_in_file)
            return True
        else:
            return False
    else:
        return False

def is_md5sum_equal(row, rep, downloaded_dir):
    """
    Takes a row in a bams dataframe and the rep prefix and determines
    whether or not the md5sum is equal to what has been downloaded.
    """
    website_md5sum = row['{}_md5sum'.format(rep)]
    filepath = exists_and_return_fullpath(row[rep],downloaded_dir)
    calculated_md5sum = get_ipython().getoutput('md5sum $filepath')
    if website_md5sum != calculated_md5sum[0].split(' ')[0]:
        print('TROUBLE: {}, {}, {}'.format(filepath, website_md5sum, calculated_md5sum))
        return False
    else:
        return True
    
def check_all_bams_for_existance(bams, downloaded_dir, to_download_file='download.sh'):
    """
    Writes and prints the files that don't exist to a file
    
    Parameters
    ----------
    bams : pandas.DataFrame
        dataframe of bams with columns defined in cols.
    to_download_file : string
        file to download (download.sh)
        
    """
    encodeproject_prefix = 'https://www.encodeproject.org/files/'
    o = open(to_download_file,'w')
    cols = ['expt_rep1','expt_rep2','control_rep1','control_rep2']
    for unused,row in bams.iterrows():
        for c in cols:
            if not(exists_and_return_fullpath(row[c],downloaded_dir)):
                print(row[c], " doesn't exist in {}.".format(downloaded_dir))
                # print("mv /projects/ps-yeolab3/encode/rnaseq/shrna_knockdown/{} ./".format(row[c]))
                o.write(
                    encodeproject_prefix + "{}/@@download/{}\n".format(
                        os.path.splitext(row[c])[0],
                        row[c]
                    )
                )
    o.close()
    
def check_md5sums(bams, downloaded_dir, md5sums_checked_file):
    """
    Checks the md5sums of the bams file
    """
    cols = ['expt_rep1','expt_rep2','control_rep1','control_rep2']
    x = tnrange(bams.shape[0])
    
    for _, row in bams.iterrows(): # for each row (RBP)
        x.update(1)
        for t in tnrange(len(cols), leave=False): # for each column (rep1, rep2, ctrl1, ctrl2)
            c = cols[t]
            filepath = exists_and_return_fullpath(row[c], downloaded_dir)
            if filepath:
                if not already_checked_md5sum(
                    os.path.join(downloaded_dir,row[c]),
                    md5sums_checked_file
                ): # if not already checked, check the md5sum
                    if is_md5sum_equal(row, c, downloaded_dir):
                        with open(md5sums_checked_file,'a') as o:
                            o.write(os.path.join(downloaded_dir,row[c]) + '\n')
                    else:
                        print(row[c], "needs to be downloaded again.")
            else:
                print(row[c], "needs to be downloaded again.")

# use: xargs -n 1 curl -O -L < FILE to download these...
def check_all_bams():
    download_hepg2_file = '/projects/ps-yeolab3/encode/rnaseq/shrna_knockdown/to_download_{}_hepg2_{}_{}'.format(aligner,lab,date)
    download_k562_file = '/projects/ps-yeolab3/encode/rnaseq/shrna_knockdown/to_download_{}_k562_{}_{}'.format(aligner,lab,date)
    check_all_bams_for_existance(hepg2_bams, downloaded_dir, download_hepg2_file)
    check_all_bams_for_existance(k562_bams, downloaded_dir, download_k562_file)

check_all_bams()

# periods indicate row progress, commas indicate rep progress
bams = hepg2_bams
md5sums_checked_file = '/projects/ps-yeolab3/encode/rnaseq/shrna_knockdown/md5sums.graveley-tophat.checked'
check_md5sums(bams, downloaded_dir, md5sums_checked_file)

bams

all_k562_bams = set(
    k562_bams['control_rep1'].append(
        k562_bams['control_rep2'].append(
            k562_bams['expt_rep1'].append(
                k562_bams['expt_rep2']
            )
        )
    )
)
all_hepg2_bams = set(
    hepg2_bams['control_rep1'].append(
        hepg2_bams['control_rep2'].append(
            hepg2_bams['expt_rep1'].append(
                hepg2_bams['expt_rep2']
            )
        )
    )
)
print(len(all_k562_bams))
print(len(all_hepg2_bams))

i = 0
jobs = ['_k562','_hepg2']
# jobs = ['_hepg2']
for bams in [k562_bams, hepg2_bams]:
    cmds = []
    for unused,row in bams.iterrows():
        p = '/home/bay001/software/subread-1.5.1-Linux-x86_64/bin/featureCounts'
        s = '/home/bay001/projects/encode/analysis/featureCounts/individual_expts/'
        o = '/home/bay001/projects/encode/analysis/featureCounts/individual_expts/{}{}.counts.txt'.format(row['name'],jobs[i])
        a = '/projects/ps-yeolab/genomes/hg19/gencode_v19/gencode.v19.annotation.gtf'
        ctrl_rep1 = exists_and_return_fullpath(row['control_rep1'],downloaded_dir)
        ctrl_rep2 = exists_and_return_fullpath(row['control_rep2'],downloaded_dir)
        expt_rep1 = exists_and_return_fullpath(row['expt_rep1'],downloaded_dir)
        expt_rep2 = exists_and_return_fullpath(row['expt_rep2'],downloaded_dir)
        cmd = '{} -s 2 --tmpDir {} -p -a {} -o {} {} {} {} {}'.format(
            p, s, a, o, ctrl_rep1, ctrl_rep2, expt_rep1, expt_rep2
        )
        cmds.append(cmd)
    qtools.Submitter(
        cmds, jobs[i], array=True, nodes=1, ppn=1, walltime='4:00:00', submit=True, queue='home-scrm', sh=s+'{}.sh'.format(jobs[i])
    )
    i = i + 1

rbp_list = ['HNRNPC','HNRNPK','SRSF1','U2AF2','U2AF1','PUF60','EIF4A3','MAGOH','PTBP1','MATR3']

expt_list = []
for rbp in rbp_list:
    expt_list.append(get_expt_from_rbp(hepg2_df,rbp,official=False))

df = make_expt_dataframe_from_expt_list(expt_list, assembly='hg19', aligner='ambiguous', lab='brenton-graveley')
df['Cell line'] = 'HepG2'

list_of_bams_to_transform = set(
    pd.concat(
        [df['expt_rep1'], df['expt_rep2'], df['control_rep1'], df['control_rep2']]
    )
)

chrom_sizes = '/projects/ps-yeolab/genomes/hg19/hg19.chrom.sizes'
output_temp_bedgraph_dir = '/home/bay001/projects/encode/analysis/rnaseq_bedgraphs/'

cmds = []
for bam in list_of_bams_to_transform:
    bam_fullpath = exists_and_return_fullpath(bam,downloaded_dir)
    output_file = os.path.join(output_temp_bedgraph_dir, '{}.bg'.format(os.path.splitext(bam)[0]))
    cmd = 'bedtools genomecov '
    cmd = cmd + '-ibam {} '.format(bam_fullpath)
    cmd = cmd + '-bg '
    cmd = cmd + '-g {} '.format(chrom_sizes)
    cmd = cmd + '> {}'.format(output_file)
    cmds.append(cmd)
qtools.Submitter(
    cmds, 'make_bedgraphs_rnaseq', array=True, nodes=1, ppn=1, walltime='4:00:00', submit=True, queue='home-scrm', sh=output_temp_bedgraph_dir+'make_bedgraphs.sh'
)

unnormalized_bedgraphs = glob.glob(output_temp_bedgraph_dir + "*.bg")
progress = tnrange(len(unnormalized_bedgraphs))

for bg in unnormalized_bedgraphs:
    bam = os.path.join(downloaded_dir, os.path.splitext(os.path.basename(bg))[0] + '.bam')
    output_file = os.path.splitext(bg)[0] + '.norm.bg'
    cmd = 'normalize_bedGraph.py '
    cmd = cmd + '--bg {} '.format(bg)
    cmd = cmd + '--bam {} '.format(bam)
    cmd = cmd + '> {}'.format(output_file)
    get_ipython().system(' samtools index $bam')
    get_ipython().system(' $cmd')
    progress.update(1)

for bam in list_of_bams_to_transform:
    bam_fullpath = exists_and_return_fullpath(bam,downloaded_dir)
    bam_softlink = os.path.join(output_temp_bedgraph_dir, os.path.basename(bam))
    get_ipython().system(' ln -s $bam_fullpath $bam_softlink')

for bam in list_of_bams_to_transform:
    bam_fullpath = exists_and_return_fullpath(bam,downloaded_dir).replace('.bam','.bam.bai')
    bam_softlink = os.path.join(output_temp_bedgraph_dir, os.path.basename(bam)).replace('.bam','.bam.bai')
    get_ipython().system(' ln -s $bam_fullpath $bam_softlink')

bedgraph_dir = '/home/bay001/projects/encode/analysis/rnaseq_bedgraphs'
def add_bedgraph_dir_r1(row):
    return os.path.join(bedgraph_dir, row['expt_rep1'])
def add_bedgraph_dir_input(row):
    return os.path.join(bedgraph_dir, row['control_rep1'])

dfx = pd.concat([df['name'], df['Cell line'], df['expt_rep1'], df['control_rep1']], axis=1).reset_index()
dfx['CLIP'] = dfx.apply(add_bedgraph_dir_r1, axis=1)
dfx['INPUT'] = dfx.apply(add_bedgraph_dir_input, axis=1)
del dfx['expt_rep1']
del dfx['control_rep1']
dfx.columns = ['uID','RBP','Cell line', 'CLIP','INPUT']
dfx.to_csv(os.path.join(bedgraph_dir + "/input_normish_manifest.tsv"), sep='\t', index=None)

df

df = pd.read_table('/projects/ps-yeolab3/encode/')

