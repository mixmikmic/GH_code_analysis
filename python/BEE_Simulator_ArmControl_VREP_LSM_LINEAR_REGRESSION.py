# Makes possible to show the output from matplotlib inline
get_ipython().magic('matplotlib inline')

import matplotlib.pyplot as plt

# Makes the figures in the PNG format:
# For more information see %config InlineBackend
get_ipython().magic("config InlineBackend.figure_formats=set([u'png'])")

plt.rcParams['figure.figsize'] = 5, 10

import numpy
import sys
import os

from sklearn import linear_model

import save_load_file as slf

import membrane_lowpass_md
membrane_lowpass = membrane_lowpass_md.membrane_lowpass

import time

# Loads the modules and starts the object to be used with the parallel processing iPython stuff...

# Remember to start the clusters:
# https://ipyparallel.readthedocs.org/en/latest/process.html

from ipyparallel import Client

cli = Client()

lbview = cli.load_balanced_view()
# dview = cli[:]

#
# Controls if the results are saved to a file
#

save2file = False

#
# This is the low-pass filter (neuron membrane) applied to the outputs:
membrane_time_constant = 30E-3

# Reducing this value reduces the "memory" of the membrane.

NofN = 20*5*6 # total number of neurons in the output
sim_step_time = 2E-3 #simulation step time (in seconds)

base_dir = "BaxterArm_VREP_simulation_data"
sim_set = "circle"

total_trials_available = 100

total_trials = 100 # This value must be the same number of files (trials) generated
                   # in BEE_Simulator_ArmControl_VREP_LSM_DATA-GENERATOR.ipynb

number_of_trajectories = 1

disconnected = False

ORIGINAL = True

size_distr=10000

trial_array = numpy.arange(1,total_trials_available+1,dtype=numpy.int)
# numpy.random.shuffle(trial_array)

#
# Creates a function to read the spikes in a (multiple process) parallel way.
#
@lbview.parallel(block=True)
def reads_files(filename):
    import save_load_file as slf 
    return slf.load_from_file_gz(filename)

#
# Here the liquid index is defined
#
# REMEMBER: it goes from ZERO to (number_of_liquids-1)

lsm_i = 0

get_ipython().run_cell_magic('time', '', '\n# \n# Loads the spikes generated by the liquid with index=lsm_i\n# \n\nfilenames = []\noutput_spikes_simulation = []\nfor pos_i in xrange(number_of_trajectories):\n    for run_i in trial_array[:total_trials]:\n        if ORIGINAL: # values from the TRAINING SET\n            filenames.append(os.getcwd()+"/"+base_dir+"/"+sim_set+"/Joint_Angles"+str(pos_i)+"_LSM_"+str(lsm_i)+"_"+str(run_i)+".gzpickle")\n        else: # values from the TESTING set\n            filenames.append(os.getcwd()+"/"+base_dir+"/"+sim_set+"/Joint_Angles"+str(pos_i)+"_LSM_RE_"+str(run_i)+".gzpickle")\n        # The format of simulated_values is (a list of tuples):\n        # [\n        # current time (in ms),    =>index 1\n        # numpy.array with spikes, =>index 2\n        # ]\n    output_spikes_simulation.append(reads_files.map(filenames))')

# 
# Prints some values (first and last time steps), just to make sure it worked...
#

print output_spikes_simulation[0][0][0]

print output_spikes_simulation[0][-1][-1]

total_trajectories,total_trials,_total_steps,sim_step_time = len(output_spikes_simulation),len(output_spikes_simulation[0]),len(output_spikes_simulation[0][0]), (output_spikes_simulation[0][0][1][0]-output_spikes_simulation[0][0][0][0])
total_trajectories,total_trials,_total_steps,sim_step_time

#
# It's important to pay attention to this:
#
total_steps=_total_steps-1
print "total_steps =",total_steps

# The readout is trained to recognise the NEXT value based on the past.
# That's why the first step is missed (there's no past as the network states are random or zero)

# Generates the FILTERED (membrane low-pass filter) data to be used with the linear regression
# The first index of the matrix is the trajectory
# Example (each trajectory has 250 steps): 
# linalg_matrix_filtered[0][0:250] => is the first experiment of the first trajectory
# linalg_matrix_filtered[0][250:250*2] => is the second experiment of the first trajectory

avoid_n = 0 # Avoids the avoid_n steps after step=0 (always ignored)
            # This type of LSM receives during the first N steps the correct values before it
            # starts generating the rest of the time series.
            # N = avoid_n+1

# t_idx = 0 # 0=>first trajectory
# e_idx = 0 # 0=>first experiment
linalg_matrix_filtered = numpy.zeros((total_trajectories, total_trials*(total_steps-avoid_n), NofN),dtype=numpy.float)

for t_idx in range(total_trajectories): # goes through all the trajectories
    for e_idx in range(total_trials): # goes through all the trials
        m_v=membrane_lowpass(NofN,membrane_time_constant) # Initialize the membrane for each new trial
        for i in range(1,total_steps): # ignores the first output from the network (noisy, uncorrelated with input)
            if (output_spikes_simulation[t_idx][e_idx][i][1]).size>0:
                m_v.process_spikes(output_spikes_simulation[t_idx][e_idx][i][1],                                   output_spikes_simulation[t_idx][e_idx][i][0])
            if i >= avoid_n: #useless as i starts at 1 and avoid_n=1...
                linalg_matrix_filtered[t_idx][(i-avoid_n)+                                              (total_steps-avoid_n)*e_idx]=m_v.check_values(i*sim_step_time) # Saves the membrane state at each time step
linalg_matrix_filtered.shape

# This is another good candidate to be vectorized...


original_joints=numpy.zeros((0,4)) #creates an empty array with the right shape...


temp=numpy.load(base_dir+"/"+sim_set+"/XY_movement_"+sim_set+".npy")
original_joints=numpy.concatenate((original_joints,temp[:1000]))

# Reads all the experiments to check which range of values is necessary to control the arm.
# At the first step (0) the network always returns zero spikes. So it's impossible to fit anything there, but zero.
# When step=0, the SNN should calculate the next value, or step+1, but because the output is zero, the
# SNN must receive this next step.
# Consequently, the SNN needs the values for step=0 and step=1 before it could be able to generate the next ones.
number_of_joints = 4
joints_all = numpy.zeros((total_steps-avoid_n,number_of_trajectories,number_of_joints),dtype=numpy.float)
for i in xrange(number_of_trajectories):
    joints=numpy.copy(original_joints)
    for j in range(number_of_joints):
        joints_all[:total_steps-avoid_n,i,j]=joints[avoid_n+1:,j] # [2:,j]
joints_all.shape

tji=0
ji=0
plt.figure(figsize=(20,10))
plt.plot(joints_all[:,tji,ji]-joints_all[0,tji,ji],'.')
plt.xlim(-10,joints_all.shape[0]+10)
plt.title("Example: Trajectory "+str(tji)+" of the joint "+str(ji))
plt.show()

# Using the idea of starting/finishing with a zero value.
#

y_s0=[]
y_s1=[]
y_e1=[]
y_w1=[]
for tji in range(number_of_trajectories):
    
    # Signal conditioning
    temp_s0=joints_all[:,tji,0]-joints_all[0,tji,0] #extract the bias
    s0_range=(temp_s0.max()-temp_s0.min()) #calculates the range after extracting the bias
    temp_s0=temp_s0/s0_range #normalizes the total range from 0 to 1

    temp_s1=joints_all[:,tji,1]-joints_all[0,tji,1]
    s1_range=(temp_s1.max()-temp_s1.min())
    temp_s1=temp_s1/s1_range

    temp_e1=joints_all[:,tji,2]-joints_all[0,tji,2]
    e1_range=(temp_e1.max()-temp_e1.min())
    temp_e1=temp_e1/e1_range

    temp_w1=joints_all[:,tji,3]-joints_all[0,tji,3]
    w1_range=(temp_w1.max()-temp_w1.min())
    temp_w1=temp_w1/w1_range

    bias_vector = joints_all[0,tji,:]

    print "Bias vector:", bias_vector
    if save2file:
        slf.save_to_file(bias_vector,"./"+base_dir+"/"+sim_set+"/bias_"+str(tji)+".pickle")    

    print "Ranges vector (output):", [s0_range,s1_range,e1_range,w1_range]      
    if save2file:
        slf.save_to_file([s0_range,s1_range,e1_range,w1_range],"./"+base_dir+"/"+sim_set+"/ranges_"+str(tji)+".pickle")
        
    # Here I'm concatenating all trials (repeating the values) in one list for each joint
    for ti in range(total_trials):
        y_s0=numpy.concatenate((y_s0,temp_s0))
        y_s1=numpy.concatenate((y_s1,temp_s1))
        y_e1=numpy.concatenate((y_e1,temp_e1))
        y_w1=numpy.concatenate((y_w1,temp_w1))

y_s0.shape,y_s1.shape,y_e1.shape,y_w1.shape

X_matrix=linalg_matrix_filtered    

X_matrix.shape

# Prepare the matrix to be used with numpy linear regression:
X_reshaped=X_matrix.reshape(y_s0.shape[0],NofN)

# Creates an empty matrix with an extra collumn with ones (numpy.linalg.lstsq demands this...)
X_reshaped=numpy.ones((X_reshaped.shape[0],X_reshaped.shape[1]+1))

# Writes the values in to the first NofN collumns
X_reshaped[:,:NofN]=X_matrix.reshape(y_s0.shape[0],NofN)

# Now the reshaped matrix has an extra collumn:
X_reshaped.shape

X=X_reshaped

numpy.shape(X)[0]*numpy.shape(X)[1]

X.max(),X.min(),y_s0.max(),y_s0.min(),y_s1.max(),y_s0.min(),y_e1.max(),y_e1.min(),y_w1.max(),y_w1.min()

X.shape, y_s0.shape

X[:,-1] # Shows the last column made of ones...

# %%time

# QR FACTORIZATION STUDY

# sklg = linear_model.LinearRegression(fit_intercept=True, normalize=True, copy_X=True, n_jobs=7)

# # Xqr_ex=numpy.concatenate((Xqr,numpy.ones((Xqr.shape[0],1))),axis=1)
# Xqr=numpy.copy(X[:,:NofN])
# q,r=numpy.linalg.qr(Xqr)

# Yqrs0=numpy.copy(y_s0)
# Yqrs1=numpy.copy(y_s1)
# Yqre1=numpy.copy(y_e1)
# Yqrw1=numpy.copy(y_w1)

# QYs0=(q.T).dot(Yqrs0)
# QYs1=(q.T).dot(Yqrs1)
# QYe1=(q.T).dot(Yqre1)
# QYw1=(q.T).dot(Yqrw1)

# sklg.fit(r,QYs0)
# c_s0=sklg.coef_
# r_s0=sklg.intercept_

# sklg.fit(r,QYs1)
# c_s1=sklg.coef_
# r_s1=sklg.intercept_

# sklg.fit(r,QYe1)
# c_e1=sklg.coef_
# r_e1=sklg.intercept_

# sklg.fit(r,QYw1)
# c_w1=sklg.coef_
# r_w1=sklg.intercept_

# @dview.parallel(block=True)
# def solve_linear_regressionQR(arguments):
#     #solve_linear_regression.map(input_list)

#     import numpy
#     from sklearn import linear_model

#     import save_load_file as slf
    
    
#     q,r,y,filename = arguments
    
#     sklg = linear_model.LinearRegression(fit_intercept=True, normalize=True, copy_X=True)
#     # sklg = linear_model.Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
#     #       normalize=False, solver='auto', tol=0.001)
#     # Using sklearn is a lot easier to try another linear model algorithm, I just have to change the above line.
#     # sklg = linear_model.SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\
#     #                                  fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\
#     #                                  loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\
#     #                                  random_state=None, shuffle=True, verbose=0, warm_start=False)

#     # sklg = linear_model.Ridge()
#     # sklg = linear_model.BayesianRidge()
    
#     QY=(q.T).dot(y)
#     sklg.fit(r,QY)

#     slf.save_to_file([sklg.coef_,sklg.intercept_],filename)
    
#     return 1

# X=X[:,:NofN] # Cuts out the extra ones used only for 

# @dview.parallel(block=True)
# def solve_linear_regression(arguments):
#     #solve_linear_regression.map(input_list)

#     import numpy
#     from sklearn import linear_model

#     import save_load_file as slf
    
    
#     X,y,NofN,xnoise,ynoise,filename = arguments
    
# #     sklg = linear_model.LinearRegression(fit_intercept=True, copy_X=True)
# #     sklg = linear_model.LinearRegression(fit_intercept=True, normalize=True, copy_X=True)    
#     # sklg = linear_model.Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
#     #       normalize=False, solver='auto', tol=0.001)
#     # Using sklearn is a lot easier to try another linear model algorithm, I just have to change the above line.
#     # sklg = linear_model.SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\
#     #                                  fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\
#     #                                  loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\
#     #                                  random_state=None, shuffle=True, verbose=0, warm_start=False)

#     sklg = linear_model.Ridge()
#     # sklg = linear_model.BayesianRidge()
    
#     # Robustly fit linear model with RANSAC algorithm
#     ransac=0
# #     sklg = linear_model.RANSACRegressor(linear_model.LinearRegression(fit_intercept=True, copy_X=True))
    

#     if (xnoise and ynoise):
#         NOISE_X = numpy.random.normal(loc=0,scale=xnoise,size=X.shape)
#         NOISE_Y = numpy.random.normal(loc=0,scale=ynoise,size=y.shape)
    
#         sklg.fit(X+NOISE_X,y+NOISE_Y)
#     else:
#         sklg.fit(X,y)

#     if not ransac:
#         slf.save_to_file([sklg.coef_,sklg.intercept_],filename)
#     else:
#         slf.save_to_file([sklg.estimator_.coef_[0,:],sklg.estimator_.intercept_[0]],filename)
    
#     return 1

# # NUMPY VERSION...
# @dview.parallel(block=True)
# def solve_linear_regression(arguments):
#     #solve_linear_regression.map(input_list)

#     import numpy
#     from sklearn import linear_model

#     import save_load_file as slf
    
    
#     X,y,NofN,xnoise,ynoise,filename = arguments
    
#     linear_regression1 = numpy.linalg.lstsq(X, y)
#     c_tau1=linear_regression1[0][:-1] # Coefficients
#     r_tau1=linear_regression1[0][-1]  # Constant
        
#     slf.save_to_file([c_tau1,r_tau1],filename)
    
#     return 1

extra_name=str(lsm_i)

if disconnected:
    extra_name="_unconnected"+extra_name

filenames = ["./"+base_dir+"/"+sim_set+"/coefficients_residues_"+str(var_name)+"_linear"+extra_name+".pickle"              for var_name in ['s0','s1','e1','w1']]

print filenames[0]

# # Tests if the two trials are identical or not...
# input_var = X
# ((input_var[0:input_var.shape[0]/2]==input_var[input_var.shape[0]/2:])==False).any()

# std_x = False
# std_y = False


# inputs_lrsq = [(X,y_s0,NofN,std_x,std_y,filenames[0]),\
#                (X,y_s1,NofN,std_x,std_y,filenames[1]),\
#                (X,y_e1,NofN,std_x,std_y,filenames[2]),\
#                (X,y_w1,NofN,std_x,std_y,filenames[3])]

# # Example of how to add all the outputs together:
# numpy.hstack((numpy.arange(10).reshape((1,10)).T,numpy.ones(10).reshape((1,10)).T))

get_ipython().run_cell_magic('time', '', '# Non parallel linear regression (trying to solve the pickles problem when I have too many trials (more than 300...))\nfrom sklearn import linear_model\n\nX=X[:,:NofN] # Cuts out the extra ones used only for \n\nsklg = linear_model.Ridge()\ny=numpy.hstack((y_s0.reshape((1,y_s0.shape[0])).T,\\\n                y_s1.reshape((1,y_s1.shape[0])).T,\\\n                y_e1.reshape((1,y_e1.shape[0])).T,\\\n                y_w1.reshape((1,y_w1.shape[0])).T))\nsklg.fit(X,y)\n\nfor fi in range(4):\n    if save2file:\n        slf.save_to_file([sklg.coef_[fi],sklg.intercept_[fi]],filenames[fi])\n    \n[c_s0,r_s0] = slf.load_from_file(filenames[0])\n[c_s1,r_s1] = slf.load_from_file(filenames[1])\n[c_e1,r_e1] = slf.load_from_file(filenames[2])\n[c_w1,r_w1] = slf.load_from_file(filenames[3])')

# %%time
# results = solve_linear_regression.map(inputs_lrsq)

# [c_s0,r_s0] = slf.load_from_file(filenames[0])
# [c_s1,r_s1] = slf.load_from_file(filenames[1])
# [c_e1,r_e1] = slf.load_from_file(filenames[2])
# [c_w1,r_w1] = slf.load_from_file(filenames[3])

# %%time
# q,r=numpy.linalg.qr(X[:,:NofN])
# inputs_lrsq_qr = [(q,r,y_s0,filenames[0]),\
#                   (q,r,y_s1,filenames[1]),\
#                   (q,r,y_e1,filenames[2]),\
#                   (q,r,y_w1,filenames[3])]

# results = solve_linear_regressionQR.map(inputs_lrsq_qr)

# [c_s0,r_s0] = slf.load_from_file(filenames[0])
# [c_s1,r_s1] = slf.load_from_file(filenames[1])
# [c_e1,r_e1] = slf.load_from_file(filenames[2])
# [c_w1,r_w1] = slf.load_from_file(filenames[3])

s0_calculated=X_matrix.reshape(y_s0.shape[0],NofN).dot(c_s0)+r_s0
s1_calculated=X_matrix.reshape(y_s1.shape[0],NofN).dot(c_s1)+r_s1
e1_calculated=X_matrix.reshape(y_e1.shape[0],NofN).dot(c_e1)+r_e1
w1_calculated=X_matrix.reshape(y_w1.shape[0],NofN).dot(c_w1)+r_w1

X_matrix.shape

# This dictionary is used to automate the figures generation
joints_dict={'s0':(y_s0,s0_calculated),'s1':(y_s1,s1_calculated),'e1':(y_e1,e1_calculated),'w1':(y_w1,w1_calculated) }

# Plots the inputs and the outputs side-by-side

joints_names = 's0','s1'

y_1 = joints_dict[joints_names[0]][0]
y_2 = joints_dict[joints_names[1]][0]
y1_calculated = joints_dict[joints_names[0]][1]
y2_calculated = joints_dict[joints_names[1]][1]

offset11 = y_1.shape[0]/number_of_trajectories
offset21 = y_2.shape[0]/number_of_trajectories

offset12 = y_1.shape[0]/number_of_trajectories/total_trials
offset22 = y_2.shape[0]/number_of_trajectories/total_trials


fig=plt.figure(figsize =(20,10));

for trajectory in xrange(number_of_trajectories):
# trajectory=0 # goes from 0 to 3

    ymax=numpy.array([y_1[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max(),y_2[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max()]).max()
    ymin=numpy.array([y_1[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min(),y_2[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min()]).min()

    ymaxLSM=numpy.array([y1_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max(),y2_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max()]).max()
    yminLSM=numpy.array([y1_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min(),y2_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min()]).min()


    plt.subplot(number_of_trajectories,2,2*trajectory+1)    
    plt.plot(y_1[trajectory*(offset11):offset11*trajectory+offset12],'b')
    plt.plot(y_2[trajectory*(offset21):offset21*trajectory+offset22],'g')


    plt.ylim(ymin-abs(ymin)/5.,ymax+abs(ymax)/5.)
    plt.title("Original analog joints "+ str(joints_names) +" - trajectory " + str(trajectory+1))

    plt.subplot(number_of_trajectories,2,2*trajectory+2)
    plt.plot(y1_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].mean(axis=0)+y1_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].std(axis=0),'r')
    plt.plot(y1_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].mean(axis=0)-y1_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].std(axis=0),'r')    
    plt.plot(y1_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].mean(axis=0),'b')    
    plt.plot(y2_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].mean(axis=0)+y2_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].std(axis=0),'r')    
    plt.plot(y2_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].mean(axis=0)-y2_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].std(axis=0),'r')        
    plt.plot(y2_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].mean(axis=0),'g')    
    plt.ylim(ymin-abs(ymin)/5.,ymax+abs(ymax)/5.)
    plt.title("LSM output (trials mean/std values) joints "+ str(joints_names) +" - trajectory " + str(trajectory+1))

# fig.subplots_adjust(bottom=0,hspace=.6) # Adjust the distance between subplots
plt.tight_layout()
# plt.savefig("./"+base_dir+"/"+sim_set+"/readout_test_s0_s1_"+sim_set+".pdf")
plt.show()

# Plots the inputs and the outputs side-by-side

joints_names = 'e1','w1'

y_1 = joints_dict[joints_names[0]][0]
y_2 = joints_dict[joints_names[1]][0]
y1_calculated = joints_dict[joints_names[0]][1]
y2_calculated = joints_dict[joints_names[1]][1]

offset11 = y_1.shape[0]/number_of_trajectories
offset21 = y_2.shape[0]/number_of_trajectories

offset12 = y_1.shape[0]/number_of_trajectories/total_trials
offset22 = y_2.shape[0]/number_of_trajectories/total_trials


fig=plt.figure(figsize =(20,10));

for trajectory in xrange(number_of_trajectories):
# trajectory=0 # goes from 0 to 3

    ymax=numpy.array([y_1[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max(),y_2[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max()]).max()
    ymin=numpy.array([y_1[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min(),y_2[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min()]).min()

    ymaxLSM=numpy.array([y1_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max(),y2_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max()]).max()
    yminLSM=numpy.array([y1_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min(),y2_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min()]).min()


    plt.subplot(number_of_trajectories,2,2*trajectory+1)    
    plt.plot(y_1[trajectory*(offset11):offset11*trajectory+offset12],'b')
    plt.plot(y_2[trajectory*(offset21):offset21*trajectory+offset22],'g')


    plt.ylim(ymin-abs(ymin)/5.,ymax+abs(ymax)/5.)
    plt.title("Original analog joints "+ str(joints_names) +" - trajectory " + str(trajectory+1))

    plt.subplot(number_of_trajectories,2,2*trajectory+2)
    plt.plot(y1_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].mean(axis=0)+y1_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].std(axis=0),'r')
    plt.plot(y1_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].mean(axis=0)-y1_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].std(axis=0),'r')    
    plt.plot(y1_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].mean(axis=0),'b')    
    plt.plot(y2_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].mean(axis=0)+y2_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].std(axis=0),'r')    
    plt.plot(y2_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].mean(axis=0)-y2_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].std(axis=0),'r')
    plt.plot(y2_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:].mean(axis=0),'g')    
    plt.ylim(ymin-abs(ymin)/5.,ymax+abs(ymax)/5.)
    plt.title("LSM output (trials mean/std values) joints "+ str(joints_names) +" - trajectory " + str(trajectory+1))

# fig.subplots_adjust(bottom=0,hspace=.6) # Adjust the distance between subplots
plt.tight_layout()
# plt.savefig("./"+base_dir+"/"+sim_set+"/readout_test_s0_s1_"+sim_set+".pdf")
plt.show()

# Plots the inputs and the outputs side-by-side

joints_names = 's0','s1'

y_1 = joints_dict[joints_names[0]][0]
y_2 = joints_dict[joints_names[1]][0]
y1_calculated = joints_dict[joints_names[0]][1]
y2_calculated = joints_dict[joints_names[1]][1]

offset11 = y_1.shape[0]/number_of_trajectories
offset21 = y_2.shape[0]/number_of_trajectories

offset12 = y_1.shape[0]/number_of_trajectories/total_trials
offset22 = y_2.shape[0]/number_of_trajectories/total_trials


fig=plt.figure(figsize =(20,10));

for trajectory in xrange(number_of_trajectories):
# trajectory=0 # goes from 0 to 3

    ymax=numpy.array([y_1[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max(),y_2[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max()]).max()
    ymin=numpy.array([y_1[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min(),y_2[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min()]).min()

    ymaxLSM=numpy.array([y1_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max(),y2_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max()]).max()
    yminLSM=numpy.array([y1_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min(),y2_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min()]).min()


    plt.subplot(number_of_trajectories,2,2*trajectory+1)    
    plt.plot(y_1[trajectory*(offset11):offset11*trajectory+offset12],'b')
    plt.plot(y_2[trajectory*(offset21):offset21*trajectory+offset22],'g')


    plt.ylim(ymin-abs(ymin)/5.,ymax+abs(ymax)/5.)
    plt.title("Original analog joints "+ str(joints_names) +" - trajectory " + str(trajectory+1))

    plt.subplot(number_of_trajectories,2,2*trajectory+2)
    for ci in range(total_trials):
        plt.plot((y1_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:])[ci,:],'b')    
        plt.plot((y2_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:])[ci,:],'g')    
    plt.ylim(ymin-abs(ymin)/5.,ymax+abs(ymax)/5.)
    plt.title("LSM output (trials mean/std values) joints "+ str(joints_names) +" - trajectory " + str(trajectory+1))

# fig.subplots_adjust(bottom=0,hspace=.6) # Adjust the distance between subplots
plt.tight_layout()
# plt.savefig("./"+base_dir+"/"+sim_set+"/readout_test_s0_s1_"+sim_set+".pdf")
plt.show()

# Plots the inputs and the outputs side-by-side

joints_names = 'e1','w1'

y_1 = joints_dict[joints_names[0]][0]
y_2 = joints_dict[joints_names[1]][0]
y1_calculated = joints_dict[joints_names[0]][1]
y2_calculated = joints_dict[joints_names[1]][1]

offset11 = y_1.shape[0]/number_of_trajectories
offset21 = y_2.shape[0]/number_of_trajectories

offset12 = y_1.shape[0]/number_of_trajectories/total_trials
offset22 = y_2.shape[0]/number_of_trajectories/total_trials


fig=plt.figure(figsize =(20,10));

for trajectory in xrange(number_of_trajectories):
# trajectory=0 # goes from 0 to 3

    ymax=numpy.array([y_1[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max(),y_2[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max()]).max()
    ymin=numpy.array([y_1[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min(),y_2[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min()]).min()

    ymaxLSM=numpy.array([y1_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max(),y2_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max()]).max()
    yminLSM=numpy.array([y1_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min(),y2_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min()]).min()


    plt.subplot(number_of_trajectories,2,2*trajectory+1)    
    plt.plot(y_1[trajectory*(offset11):offset11*trajectory+offset12],'b')
    plt.plot(y_2[trajectory*(offset21):offset21*trajectory+offset22],'g')


    plt.ylim(ymin-abs(ymin)/5.,ymax+abs(ymax)/5.)
    plt.title("Original analog joints "+ str(joints_names) +" - trajectory " + str(trajectory+1))

    plt.subplot(number_of_trajectories,2,2*trajectory+2)
    for ci in range(total_trials):
        plt.plot((y1_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:])[ci,:],'b')    
        plt.plot((y2_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:])[ci,:],'g')    
    plt.ylim(ymin-abs(ymin)/5.,ymax+abs(ymax)/5.)
    plt.title("LSM output (trials mean/std values) joints "+ str(joints_names) +" - trajectory " + str(trajectory+1))

# fig.subplots_adjust(bottom=0,hspace=.6) # Adjust the distance between subplots
plt.tight_layout()
# plt.savefig("./"+base_dir+"/"+sim_set+"/readout_test_s0_s1_"+sim_set+".pdf")
plt.show()

Ninput = 150 # Number of neurons used for the input code
joint_values_normalised = numpy.linspace(-1,1,Ninput)

# [abs(joint_values_normalised-jin).argmin() for jin in XXXX]

# Plots the inputs and the outputs side-by-side

joints_names = 's0','s1'

y_1 = joints_dict[joints_names[0]][0]
y_2 = joints_dict[joints_names[1]][0]
y1_calculated = joints_dict[joints_names[0]][1]
y2_calculated = joints_dict[joints_names[1]][1]

offset11 = y_1.shape[0]/number_of_trajectories
offset21 = y_2.shape[0]/number_of_trajectories

offset12 = y_1.shape[0]/number_of_trajectories/total_trials
offset22 = y_2.shape[0]/number_of_trajectories/total_trials


fig=plt.figure(figsize =(20,10));

for trajectory in xrange(number_of_trajectories):
# trajectory=0 # goes from 0 to 3

    ymax=numpy.array([y_1[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max(),y_2[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max()]).max()
    ymin=numpy.array([y_1[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min(),y_2[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min()]).min()

    ymaxLSM=numpy.array([y1_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max(),y2_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max()]).max()
    yminLSM=numpy.array([y1_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min(),y2_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min()]).min()

    j1=numpy.array([abs(joint_values_normalised-jin).argmin() for jin in y_1[trajectory*(offset11):offset11*trajectory+offset12]])
    j2=numpy.array([abs(joint_values_normalised-jin).argmin() for jin in y_2[trajectory*(offset21):offset21*trajectory+offset22]])
    plt.subplot(number_of_trajectories,2,2*trajectory+1)    
    plt.plot(j1,'b')
    plt.plot(j2,'g')

    plt.title("Original (discretised) joints "+ str(joints_names) +" - trajectory " + str(trajectory+1))

    plt.subplot(number_of_trajectories,2,2*trajectory+2)
    ans1 = []
    ans2 = []
    for ci in range(total_trials):
        j1ci = numpy.array([abs(joint_values_normalised-jin).argmin() for jin in (y1_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:])[ci,:]])
        j2ci = numpy.array([abs(joint_values_normalised-jin).argmin() for jin in (y2_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:])[ci,:]])
        ans1.append(abs(j1ci-j1))
        ans2.append(abs(j2ci-j2))

    ans1=numpy.concatenate(ans1)
    ans2=numpy.concatenate(ans2)    
    n, bins1, patches = plt.hist(numpy.log2(ans1+1),log=True,normed=True,alpha=0.5)
    n, bins2, patches = plt.hist(numpy.log2(ans2+1),log=True,normed=True,alpha=0.5)
    if max(bins1)>max(bins2):
        bins=bins1
    else:
        bins=bins2
    plt.xticks(bins, ["{0:.2f}".format(2**i-1) for i in bins])    
    plt.title("Histogram of errors (log and normalised) joints "+ str(joints_names) +" - trajectory " + str(trajectory+1))

# fig.subplots_adjust(bottom=0,hspace=.6) # Adjust the distance between subplots
plt.tight_layout()
# plt.savefig("./"+base_dir+"/"+sim_set+"/readout_test_s0_s1_"+sim_set+".pdf")
plt.show()

# Generates the discrete distribution
# The cell ABOVE must be execute JUST BEFORE THIS ONE!

ans1 = []
ans2 = []
for ci in range(total_trials):
    j1ci = numpy.array([abs(joint_values_normalised-jin).argmin() for jin in (y1_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:])[ci,:]])
    j2ci = numpy.array([abs(joint_values_normalised-jin).argmin() for jin in (y2_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:])[ci,:]])
    ans1.append((j1ci-j1))
    ans2.append((j2ci-j2))

ans1=numpy.concatenate(ans1)
ans2=numpy.concatenate(ans2)   

n1, bins1 = numpy.histogram(ans1)
n2, bins2 = numpy.histogram(ans2)

norm_distr1 = (n1*size_distr/n1.sum()).astype(dtype=numpy.int)
coeff_distr1 = (numpy.round(bins1)).astype(dtype=numpy.int)
norm_distr2 = (n2*size_distr/n2.sum()).astype(dtype=numpy.int)
coeff_distr2 = (numpy.round(bins2)).astype(dtype=numpy.int)

distr1 = numpy.zeros(len(numpy.unique(coeff_distr1)),dtype=numpy.int)
distr2 = numpy.zeros(len(numpy.unique(coeff_distr2)),dtype=numpy.int)

for i in range(len(norm_distr1)):
    distr1[abs(numpy.unique(coeff_distr1)-coeff_distr1[i]).argmin()]+=norm_distr1[i]
print distr1,numpy.unique(coeff_distr1)
filename = "./"+base_dir+"/"+sim_set+"/noise_distr_"+joints_names[0]+"_linear"+extra_name+".pickle"
if save2file:
    slf.save_to_file((size_distr,distr1,numpy.unique(coeff_distr1)),filename)

for i in range(len(norm_distr2)):
    distr2[abs(numpy.unique(coeff_distr2)-coeff_distr2[i]).argmin()]+=norm_distr2[i]
print distr2,numpy.unique(coeff_distr2)
filename = "./"+base_dir+"/"+sim_set+"/noise_distr_"+joints_names[1]+"_linear"+extra_name+".pickle"
if save2file:
    slf.save_to_file((size_distr,distr2,numpy.unique(coeff_distr2)),filename)

# Plots the inputs and the outputs side-by-side

joints_names = 'e1','w1'

y_1 = joints_dict[joints_names[0]][0]
y_2 = joints_dict[joints_names[1]][0]
y1_calculated = joints_dict[joints_names[0]][1]
y2_calculated = joints_dict[joints_names[1]][1]

offset11 = y_1.shape[0]/number_of_trajectories
offset21 = y_2.shape[0]/number_of_trajectories

offset12 = y_1.shape[0]/number_of_trajectories/total_trials
offset22 = y_2.shape[0]/number_of_trajectories/total_trials


fig=plt.figure(figsize =(20,10));

for trajectory in xrange(number_of_trajectories):
# trajectory=0 # goes from 0 to 3

    ymax=numpy.array([y_1[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max(),y_2[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max()]).max()
    ymin=numpy.array([y_1[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min(),y_2[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min()]).min()

    ymaxLSM=numpy.array([y1_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max(),y2_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].max()]).max()
    yminLSM=numpy.array([y1_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min(),y2_calculated[trajectory*(total_trials*total_steps):total_steps*(1+trajectory*(total_trials*total_steps))].min()]).min()

    j1=numpy.array([abs(joint_values_normalised-jin).argmin() for jin in y_1[trajectory*(offset11):offset11*trajectory+offset12]])
    j2=numpy.array([abs(joint_values_normalised-jin).argmin() for jin in y_2[trajectory*(offset21):offset21*trajectory+offset22]])
    plt.subplot(number_of_trajectories,2,2*trajectory+1)    
    plt.plot(j1,'b')
    plt.plot(j2,'g')

    plt.title("Original (discretised) joints "+ str(joints_names) +" - trajectory " + str(trajectory+1))

    plt.subplot(number_of_trajectories,2,2*trajectory+2)
    ans1 = []
    ans2 = []
    for ci in range(total_trials):
        j1ci = numpy.array([abs(joint_values_normalised-jin).argmin() for jin in (y1_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:])[ci,:]])
        j2ci = numpy.array([abs(joint_values_normalised-jin).argmin() for jin in (y2_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:])[ci,:]])
        ans1.append(abs(j1ci-j1))
        ans2.append(abs(j2ci-j2))

    ans1=numpy.concatenate(ans1)
    ans2=numpy.concatenate(ans2)    
    n1, bins1, patches = plt.hist(numpy.log2(ans1+1),log=True,normed=True,alpha=0.5)
    n2, bins2, patches = plt.hist(numpy.log2(ans2+1),log=True,normed=True,alpha=0.5)
    if max(bins1)>max(bins2):
        bins=bins1
    else:
        bins=bins2
    plt.xticks(bins, ["{0:.2f}".format(2**i-1) for i in bins])    
    plt.title("Histogram of errors (log and normalised) joints "+ str(joints_names) +" - trajectory " + str(trajectory+1))

# fig.subplots_adjust(bottom=0,hspace=.6) # Adjust the distance between subplots
plt.tight_layout()
# plt.savefig("./"+base_dir+"/"+sim_set+"/readout_test_s0_s1_"+sim_set+".pdf")
plt.show()

# Generates the discrete distribution
# The cell ABOVE must be execute JUST BEFORE THIS ONE!

ans1 = []
ans2 = []
for ci in range(total_trials):
    j1ci = numpy.array([abs(joint_values_normalised-jin).argmin() for jin in (y1_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:])[ci,:]])
    j2ci = numpy.array([abs(joint_values_normalised-jin).argmin() for jin in (y2_calculated.reshape(number_of_trajectories,total_trials,total_steps-avoid_n)[trajectory,:,:])[ci,:]])
    ans1.append((j1ci-j1))
    ans2.append((j2ci-j2))

ans1=numpy.concatenate(ans1)
ans2=numpy.concatenate(ans2)   

n1, bins1 = numpy.histogram(ans1)
n2, bins2 = numpy.histogram(ans2)

norm_distr1 = (n1*size_distr/n1.sum()).astype(dtype=numpy.int)
coeff_distr1 = (numpy.round(bins1)).astype(dtype=numpy.int)
norm_distr2 = (n2*size_distr/n2.sum()).astype(dtype=numpy.int)
coeff_distr2 = (numpy.round(bins2)).astype(dtype=numpy.int)

distr1 = numpy.zeros(len(numpy.unique(coeff_distr1)),dtype=numpy.int)
distr2 = numpy.zeros(len(numpy.unique(coeff_distr2)),dtype=numpy.int)

for i in range(len(norm_distr1)):
    distr1[abs(numpy.unique(coeff_distr1)-coeff_distr1[i]).argmin()]+=norm_distr1[i]
print distr1,numpy.unique(coeff_distr1)
filename = "./"+base_dir+"/"+sim_set+"/noise_distr_"+joints_names[0]+"_linear"+extra_name+".pickle"
if save2file:
    slf.save_to_file((size_distr,distr1,numpy.unique(coeff_distr1)),filename)

for i in range(len(norm_distr2)):
    distr2[abs(numpy.unique(coeff_distr2)-coeff_distr2[i]).argmin()]+=norm_distr2[i]
print distr2,numpy.unique(coeff_distr2)
filename = "./"+base_dir+"/"+sim_set+"/noise_distr_"+joints_names[1]+"_linear"+extra_name+".pickle"
if save2file:
    slf.save_to_file((size_distr,distr2,numpy.unique(coeff_distr2)),filename)

plt.rcParams['figure.figsize'] = 30, 10

# plt.figure(figsize =(30,10))
plt.plot(c_s0,'v',label="S0")
plt.title("Coefficients")
plt.legend()
plt.show()

plt.plot(c_s1,'s',label="S1")
plt.title("Coefficients")
plt.legend()
plt.show()

plt.plot(c_e1,'o',label="E1")
plt.title("Coefficients")
plt.legend()
plt.show()

plt.plot(c_w1,'x',label="W1")
plt.title("Coefficients")
plt.legend()
plt.show()

# Independent terms
r_s0,r_s1,r_e1,r_w1

# Independent terms close to zero are the result of the bias extraction (I force the curves to start at zero)

readout_w = [c_s0,c_s1,c_e1,c_w1]
readout_w_n = ['S0','S1','E1','W1'] 

#
# Here the readout weights are plotted as a matrix instead of a line
# to make it easier to visualise / compare their values.
for wi,ti in zip(readout_w,readout_w_n):
    plt.figure(figsize =(10,10))
    plt.imshow(wi.reshape((30,20)), origin='lower', aspect='auto',interpolation='none')
    # plt.axis('off')
    plt.set_cmap('spectral')
    plt.colorbar()
    plt.title("Readout Weights After Learning - "+ti)
    plt.show()



